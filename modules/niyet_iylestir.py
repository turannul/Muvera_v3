# modules/niyet_iylestir.py â€” verbose with timings (no argparse, no env)
from __future__ import annotations
import os, json, re, time, math
import pandas as pd
from sentence_transformers import SentenceTransformer, util

# ============== CONFIG (edit here) ==============
MODE = "niyet"                     # "niyet" | "sorgu" | "both"
MIN_IMPROVE = 0.005
MAX_ATTEMPTS = 1
ONLY_IMPROVED = False
OLLAMA_MODEL = "gemma3:4b"
# ===============================================

# ---- paths ----
try:
    from config import output_dir as _OUT
except Exception:
    _OUT = os.path.join("data", "output")
os.makedirs(_OUT, exist_ok=True)

NIYET_IN_CSV  = os.path.join(_OUT, "icerik_niyet_top10.csv")
SORGU_IN_CSV  = os.path.join(_OUT, "icerik_sorgu_top10.csv")
NIYET_OUT_CSV = os.path.join(_OUT, "icerik_niyet_iyilestirme.csv")
SORGU_OUT_CSV = os.path.join(_OUT, "icerik_sorgu_iyilestirme.csv")

# ---- model ----
try:
    from config import model as _cfg_model  # instance or callable
    st_model = _cfg_model() if callable(_cfg_model) else _cfg_model
except Exception:
    st_model = SentenceTransformer("emrecan/bert-base-turkish-cased-mean-nli-stsb-tr")

# ---- optional prompts ----
try:
    from modules.prompt.niyet_prompt import generate_niyet_prompt as _gen_niyet_prompt
except Exception:
    _gen_niyet_prompt = None
try:
    from modules.prompt.sorgu_prompt import generate_sorgu_prompt as _gen_sorgu_prompt
except Exception:
    _gen_sorgu_prompt = None

# ============== UTIL ==============
def now() -> str:
    t = time.localtime()
    return time.strftime("%H:%M:%S", t)

def fmt_sec(s: float) -> str:
    if s < 1:
        return f"{s*1000:.0f} ms"
    m, r = divmod(s, 60)
    if m < 1:
        return f"{s:.2f} s"
    return f"{int(m)}m {r:.1f}s"

def _read_csv_robust(path: str) -> pd.DataFrame:
    t0 = time.time()
    print(f"[{now()}] â¬‡ï¸  Reading CSV: {path}", flush=True)
    for enc in (None, "utf-8", "utf-8-sig", "latin-1"):
        try:
            df = pd.read_csv(path, encoding=enc) if enc else pd.read_csv(path)
            print(f"[{now()}] âœ… CSV loaded ({len(df)} rows) in {fmt_sec(time.time()-t0)}", flush=True)
            return df
        except Exception:
            continue
    raise RuntimeError(f"CSV okunamadÄ±: {path}")

def _pick_col(df: pd.DataFrame, names):
    low = {c.lower(): c for c in df.columns}
    for n in names:
        if n in df.columns: return n
        if n.lower() in low: return low[n.lower()]
    def norm(s): return re.sub(r"[Ä°IÄ±]", "i", s, flags=re.I).lower()
    norm_map = {norm(c): c for c in df.columns}
    for n in names:
        if norm(n) in norm_map: return norm_map[norm(n)]
    return None

def _norm_score(x) -> float:
    s = str(x if x is not None else "").replace("%", "").replace(",", ".").strip()
    m = re.findall(r"[-+]?\d*\.?\d+", s)
    if not m: return 0.0
    v = float(m[0])
    return round(v/100.0, 6) if v > 1.5 else round(v, 6)

def _similarity(a_text: str, b_text: str) -> float:
    if not a_text or not b_text: return 0.0
    a = st_model.encode(a_text, convert_to_tensor=True, normalize_embeddings=True)
    b = st_model.encode(b_text,  convert_to_tensor=True, normalize_embeddings=True)
    return float(util.cos_sim(a, b).item())

def _run_llm(prompt: str) -> str:
    from ollama import chat
    t0 = time.time()
    print(f"    [{now()}] ğŸ” LLM call â†’ {OLLAMA_MODEL} (prompt chars: {len(prompt)})", flush=True)
    resp = chat(model=OLLAMA_MODEL, messages=[{"role": "user", "content": prompt}])
    out = resp.get("message", {}).get("content", str(resp))
    print(f"    [{now()}] âœ… LLM done in {fmt_sec(time.time()-t0)}", flush=True)
    return out

def _parse_llm_json(text: str) -> dict:
    m = re.search(r"\{.*\}", text, flags=re.S)
    if not m: raise ValueError("LLM yanÄ±tÄ±nda JSON bulunamadÄ±.")
    return json.loads(m.group(0))

# ---- prompt builders ----
NIYET_SYS = (
    "Sen bir SEO ve iÃ§erik geliÅŸtirme uzmanÄ±sÄ±n. "
    "GÃ¶revin, kullanÄ±cÄ± niyetine gÃ¶re mevcut metni kÃ¼Ã§Ã¼k dokunuÅŸlarla iyileÅŸtirmek. "
    "h1/h2: niyeti doÄŸrudan karÅŸÄ±layan baÅŸlÄ±k; p/div: +5â€“10 kelime; li: +1â€“2 kelime. "
    "AnlamÄ± bozma, pazarlama kliÅŸeleri ekleme. Sadece geÃ§erli JSON dÃ¶ndÃ¼r."
)
NIYET_HUM = """
Girdi:
KullanÄ±cÄ± Niyeti: "{intent}"
Mevcut Ä°Ã§erik: "{current}"
HTML BÃ¶lÃ¼mÃ¼: "{tag}"
Eski Skor: {old}

Beklenen Ã§Ä±ktÄ± (JSON):
{{
  "KullanÄ±cÄ± Niyeti": "{intent}",
  "Mevcut Ä°Ã§erik": "{current}",
  "GeliÅŸtirilmiÅŸ Ä°Ã§erik": "Buraya geliÅŸtirilmiÅŸ hali gelecek",
  "HTML BÃ¶lÃ¼mÃ¼": "{tag}"
}}
""".strip()

def _build_niyet_prompt(intent, current, tag, old):
    if _gen_niyet_prompt:
        try:
            return _gen_niyet_prompt(intent, current, tag, old)
        except Exception:
            pass
    return f"{NIYET_SYS}\n{NIYET_HUM.format(intent=intent, current=current, tag=tag, old=old)}"

def _build_sorgu_prompt(query, current, tag, old):
    if _gen_sorgu_prompt:
        try:
            return _gen_sorgu_prompt(query, current, tag, old)
        except Exception:
            pass
    return _build_niyet_prompt(query, current, tag, old)\
           .replace("KullanÄ±cÄ± Niyeti", "KullanÄ±cÄ± Sorgusu")\
           .replace("GeliÅŸtirilmiÅŸ Ä°Ã§erik", "GeliÅŸtirilmiÅŸ Metin")

# ---- core improve ----
def _try_improve(mode, query_text, current_text, html_tag, old_score,
                 min_improve=MIN_IMPROVE, max_attempts=MAX_ATTEMPTS):
    best_text = current_text
    best_score = old_score if old_score > 0 else _similarity(query_text, current_text)

    for attempt in range(1, max_attempts+1):
        print(f"    [{now()}] attempt {attempt}/{max_attempts} | baseline={best_score:.4f}", flush=True)
        prompt = _build_niyet_prompt(query_text, best_text, html_tag, best_score) if mode == "niyet" \
                 else _build_sorgu_prompt(query_text, best_text, html_tag, best_score)
        data = _parse_llm_json(_run_llm(prompt))

        cand = (
            data.get("GeliÅŸtirilmiÅŸ Ä°Ã§erik") if mode == "niyet"
            else data.get("GeliÅŸtirilmiÅŸ Metin")
        )
        if not isinstance(cand, str) or not cand.strip():
            print("    â†ªï¸  LLM returned empty candidate; keeping current text", flush=True)
            cand = best_text

        new_score = _similarity(query_text, cand)
        print(f"    [{now()}] scored new={new_score:.4f} (delta={(new_score-best_score):+.4f})", flush=True)

        if new_score >= best_score * (1.0 + min_improve):
            print(f"    ğŸ¯ improved â‰¥ {min_improve*100:.2f}% â€” accepting", flush=True)
            return cand, new_score

        if new_score > best_score:
            print("    â¬†ï¸  slight improvement; updating baseline and retrying (if attempts left)", flush=True)
            best_text, best_score = cand, new_score

    print("    âš–ï¸  no sufficient improvement; returning best so far", flush=True)
    return best_text, best_score

# ============== FLOWS ==============
def run_niyet_flow(min_improve=MIN_IMPROVE, max_attempts=MAX_ATTEMPTS, only_improved=ONLY_IMPROVED) -> str:
    t_flow = time.time()
    df = _read_csv_robust(NIYET_IN_CSV)

    c_intent = _pick_col(df, ["KullanÄ±cÄ± Niyeti","Kullanici Niyeti","Niyet","Intent"])
    c_html   = _pick_col(df, ["HTML KaynaÄŸÄ±","HTML Kaynagi","HTML BÃ¶lÃ¼mÃ¼","HTML Section"])
    c_text   = _pick_col(df, ["Web Ä°Ã§eriÄŸi","Web Icerigi","Ä°Ã§erik","Icerik","Metin","Content"])
    c_score  = _pick_col(df, ["Benzerlik Skoru","Skor","Score","Similarity Score","similarity_score"])
    for need, name in [(c_intent,"KullanÄ±cÄ± Niyeti"), (c_html,"HTML KaynaÄŸÄ±"), (c_text,"Web Ä°Ã§eriÄŸi")]:
        if not need: raise KeyError(f"Eksik kolon: {name}")

    total = len(df)
    kept = improved = 0
    rows = []

    print(f"[{now()}] ğŸš€ NIYET flow start | rows={total} | MIN_IMPROVE={min_improve} | MAX_ATTEMPTS={max_attempts}", flush=True)

    for idx, r in df.iterrows():
        r_t0 = time.time()
        intent = str(r[c_intent] or "")
        tag    = str(r[c_html] or "")
        cur    = str(r[c_text] or "")
        old    = _norm_score(r[c_score]) if c_score else _similarity(intent, cur)

        print(f"\n[{now()}] â†’ Row {idx+1}/{total} | tag='{tag}' | old={old:.4f}", flush=True)
        cand, new = _try_improve("niyet", intent, cur, tag, old, min_improve, max_attempts)

        if only_improved and new < old * (1.0 + min_improve):
            print(f"   âœ– not enough improvement ({((new-old)/max(old,1e-8))*100:.2f}%) â€” skipping", flush=True)
        else:
            improved += 1 if new > old else 0
            kept += 1
            change_pct = (new - old) / max(old, 1e-8) * 100.0
            rows.append({
                "KullanÄ±cÄ± Niyeti": intent,
                "Mevcut Ä°Ã§erik": cur,
                "GeliÅŸtirilmiÅŸ Ä°Ã§erik": cand,
                "HTML BÃ¶lÃ¼mÃ¼": tag,
                "Eski Skor": round(float(old), 6),
                "Yeni Skor": round(float(new), 6),
                "YÃ¼zde DeÄŸiÅŸim": round(float(change_pct), 2),
            })
            print(f"   âœ… kept (Î”={change_pct:+.2f}%)", flush=True)

        print(f"   â± row time: {fmt_sec(time.time()-r_t0)}", flush=True)

    out_df = pd.DataFrame(rows)
    out_df.to_csv(NIYET_OUT_CSV, index=False, encoding="utf-8")
    print(f"\n[{now()}] ğŸ’¾ NIYET saved â†’ {NIYET_OUT_CSV} (rows kept={kept}, improved={improved})", flush=True)
    print(f"[{now()}] ğŸ NIYET flow finished in {fmt_sec(time.time()-t_flow)}\n", flush=True)
    return NIYET_OUT_CSV

def run_sorgu_flow(min_improve=MIN_IMPROVE, max_attempts=MAX_ATTEMPTS, only_improved=ONLY_IMPROVED) -> str:
    t_flow = time.time()
    df = _read_csv_robust(SORGU_IN_CSV)

    c_query = _pick_col(df, ["KullanÄ±cÄ± Sorgusu","Kullanici Sorgusu","Sorgu","Query","Aranan Sorgu"])
    c_html  = _pick_col(df, ["HTML KaynaÄŸÄ±","HTML Kaynagi","HTML BÃ¶lÃ¼mÃ¼","HTML Section"])
    c_text  = _pick_col(df, ["Web Ä°Ã§eriÄŸi","Web Icerigi","Ä°Ã§erik","Icerik","Metin","Content"])
    c_score = _pick_col(df, ["Benzerlik Skoru","Skor","Score","Similarity Score","similarity_score"])
    for need, name in [(c_query,"KullanÄ±cÄ± Sorgusu"), (c_html,"HTML KaynaÄŸÄ±"), (c_text,"Web Ä°Ã§eriÄŸi")]:
        if not need: raise KeyError(f"Eksik kolon: {name}")

    total = len(df)
    kept = improved = 0
    rows = []

    print(f"[{now()}] ğŸš€ SORGU flow start | rows={total} | MIN_IMPROVE={min_improve} | MAX_ATTEMPTS={max_attempts}", flush=True)

    for idx, r in df.iterrows():
        r_t0 = time.time()
        q   = str(r[c_query] or "")
        tag = str(r[c_html] or "")
        cur = str(r[c_text] or "")
        old = _norm_score(r[c_score]) if c_score else _similarity(q, cur)

        print(f"\n[{now()}] â†’ Row {idx+1}/{total} | tag='{tag}' | old={old:.4f}", flush=True)
        cand, new = _try_improve("sorgu", q, cur, tag, old, min_improve, max_attempts)

        if only_improved and new < old * (1.0 + min_improve):
            print(f"   âœ– not enough improvement ({((new-old)/max(old,1e-8))*100:.2f}%) â€” skipping", flush=True)
        else:
            improved += 1 if new > old else 0
            kept += 1
            change_pct = (new - old) / max(old, 1e-8) * 100.0
            rows.append({
                "HTML BÃ¶lÃ¼mÃ¼": tag,
                "KullanÄ±cÄ± Sorgusu": q,
                "Eski Metin": cur,
                "GeliÅŸtirilmiÅŸ Metin": cand,
                "Eski Skor": round(float(old), 6),
                "Yeni Skor": round(float(new), 6),
                "YÃ¼zde DeÄŸiÅŸim": round(float(change_pct), 2),
            })
            print(f"   âœ… kept (Î”={change_pct:+.2f}%)", flush=True)

        print(f"   â± row time: {fmt_sec(time.time()-r_t0)}", flush=True)

    out_df = pd.DataFrame(rows)
    out_df.to_csv(SORGU_OUT_CSV, index=False, encoding="utf-8")
    print(f"\n[{now()}] ğŸ’¾ SORGU saved â†’ {SORGU_OUT_CSV} (rows kept={kept}, improved={improved})", flush=True)
    print(f"[{now()}] ğŸ SORGU flow finished in {fmt_sec(time.time()-t_flow)}\n", flush=True)
    return SORGU_OUT_CSV

# ============== MAIN ==============
def main():
    t_all = time.time()
    print(f"[{now()}] âš™ï¸  START niyet_iylestir.py", flush=True)
    print(f"    MODE={MODE} | MIN_IMPROVE={MIN_IMPROVE} | MAX_ATTEMPTS={MAX_ATTEMPTS} | ONLY_IMPROVED={ONLY_IMPROVED}", flush=True)
    print(f"    INPUTS: NIYET_IN={NIYET_IN_CSV} | SORGU_IN={SORGU_IN_CSV}", flush=True)
    print(f"    OUTPUTS: NIYET_OUT={NIYET_OUT_CSV} | SORGU_OUT={SORGU_OUT_CSV}", flush=True)

    outputs = []
    if MODE in ("niyet", "both"):
        outputs.append(run_niyet_flow())
    if MODE in ("sorgu", "both"):
        outputs.append(run_sorgu_flow())

    print(f"[{now()}] âœ… DONE in {fmt_sec(time.time()-t_all)}", flush=True)
    for p in outputs:
        print(f"   â€¢ {os.path.abspath(p)}", flush=True)

if __name__ == "__main__":
    main()
